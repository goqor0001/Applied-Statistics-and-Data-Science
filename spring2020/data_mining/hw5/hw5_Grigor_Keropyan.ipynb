{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = open('train.json','r').read()\n",
    "train_json = json.loads(train)\n",
    "test = open('test.json','r').read()\n",
    "test_json = json.loads(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39774"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, cuisine, ingredient_list]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df_dict = dict()\n",
    "df_dict['id']=[]\n",
    "df_dict['cuisine']=[]\n",
    "df_dict['ingredient_list'] = []\n",
    "train_df = pd.DataFrame(df_dict, dtype=np.int64)\n",
    "test_df = train_df.copy()\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 28583,\n",
       " 'ingredients': ['sugar',\n",
       "  'egg yolks',\n",
       "  'corn starch',\n",
       "  'cream of tartar',\n",
       "  'bananas',\n",
       "  'vanilla wafers',\n",
       "  'milk',\n",
       "  'vanilla extract',\n",
       "  'toasted pecans',\n",
       "  'egg whites',\n",
       "  'light rum']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_json[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 10259,\n",
       " 'cuisine': 'greek',\n",
       " 'ingredients': ['romaine lettuce',\n",
       "  'black olives',\n",
       "  'grape tomatoes',\n",
       "  'garlic',\n",
       "  'pepper',\n",
       "  'purple onion',\n",
       "  'seasoning',\n",
       "  'garbanzo beans',\n",
       "  'feta cheese crumbles']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_json[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id      cuisine                                    ingredient_list\n",
      "0  10259        greek  romaine_lettuce black_olives grape_tomatoes ga...\n",
      "1  25693  southern_us  plain_flour ground_pepper salt tomatoes ground...\n",
      "2  20130     filipino  eggs pepper salt mayonaise cooking_oil green_c...\n",
      "3  22213       indian                     water vegetable_oil wheat salt\n",
      "4  13162       indian  black_pepper shallots cornflour cayenne_pepper...\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for curr_json in train_json:    \n",
    "    ingredient_list = \" \".join([re.sub('\\s', \"_\", ingredient) for ingredient in curr_json['ingredients']])\n",
    "    train_df.loc[i] = [curr_json['id'], curr_json['cuisine'], ingredient_list]\n",
    "    i+=1\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                                    ingredient_list\n",
      "0  18009  baking_powder eggs all-purpose_flour raisins m...\n",
      "1  28583  sugar egg_yolks corn_starch cream_of_tartar ba...\n",
      "2  41580  sausage_links fennel_bulb fronds olive_oil cub...\n",
      "3  29752  meat_cuts file_powder smoked_sausage okra shri...\n",
      "4  35687  ground_black_pepper salt sausage_casings leeks...\n"
     ]
    }
   ],
   "source": [
    "test_df.drop(['cuisine'], 1, inplace=True)\n",
    "i = 0\n",
    "for curr_json in test_json:    \n",
    "    ingredient_list = \" \".join([ re.sub('\\s',\"_\",ingredient) for ingredient in curr_json['ingredients'] ])\n",
    "    test_df.loc[i] =  [curr_json['id'], ingredient_list]\n",
    "    i+=1\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          greek\n",
      "1    southern_us\n",
      "2       filipino\n",
      "3         indian\n",
      "4         indian\n",
      "Name: cuisine, dtype: object\n"
     ]
    }
   ],
   "source": [
    "Y_train = train_df['cuisine']\n",
    "train_df.drop('cuisine', 1, inplace=True)\n",
    "print(Y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39774, 2) (9944, 2)\n",
      "(49718, 2)\n",
      "(49718, 7299)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "X = train_df.append(test_df)\n",
    "print(X.shape)\n",
    "\n",
    "ingredient_list = X['ingredient_list']\n",
    "cv = CountVectorizer().fit(ingredient_list)\n",
    "ingredient_list_count = cv.transform(ingredient_list)\n",
    "print(ingredient_list_count.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49718, 7299)\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer().fit(ingredient_list_count)\n",
    "ingredient_list_tfidf = tfidf_transformer.transform(ingredient_list_count)\n",
    "print(ingredient_list_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :(31819, 7299)(31819,), test: (9944, 7299) index: (9944,), validation: (7955, 7299)(7955,)\n"
     ]
    }
   ],
   "source": [
    "X_train = ingredient_list_tfidf[:39774]\n",
    "X_test = ingredient_list_tfidf[39774:]\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X_train,Y_train,test_size=0.2)\n",
    "X_test_index = test_df['id']\n",
    "print(f\"train :{X_train.shape}{Y_train.shape}, test: {X_test.shape} index: {X_test_index.shape}, validation: {X_validation.shape}{Y_validation.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(Y_train.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(20),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classifiers) == len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, clf in zip(names, classifiers):\n",
    "\n",
    "    clf.fit(X_train, Y_train)\n",
    "    score = clf.score(X_validation, Y_validation)\n",
    "#     print(name, score)\n",
    "    results[name] = [clf, score]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Nearest Neighbors': [KNeighborsClassifier(n_neighbors=20),\n",
       "  0.732872407291012],\n",
       " 'Linear SVM': [SVC(C=0.025, kernel='linear'), 0.5509742300439975],\n",
       " 'RBF SVM': [SVC(C=1, gamma=2), 0.7453174104336895],\n",
       " 'Decision Tree': [DecisionTreeClassifier(max_depth=5), 0.3048397234443746],\n",
       " 'Random Forest': [RandomForestClassifier(max_depth=5, max_features=1, n_estimators=10),\n",
       "  0.20791954745443117],\n",
       " 'Neural Net': [MLPClassifier(alpha=1, max_iter=1000), 0.5700817096165933],\n",
       " 'AdaBoost': [AdaBoostClassifier(), 0.4861093651791326]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = results['RBF SVM'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9944,)\n"
     ]
    }
   ],
   "source": [
    "predictions = svm_clf.predict(X_test)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame({\n",
    "    \"id\": X_test_index,\n",
    "    \"cuisine\": predictions\n",
    "})\n",
    "res.to_csv(\"result.csv\",header=True,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
